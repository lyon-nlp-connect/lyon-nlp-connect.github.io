{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GPT Model from Scratch\n",
        "\n",
        "This notebook implements a GPT-style Transformer model from the ground up.\n",
        "\n",
        "- Reference: [Transformers from Scratch](https://e2eml.school/transformers.html) — a clear and visual explanation of the architecture.\n",
        "- Based on the video by Andrej Karpathy: [Let's Build GPT](https://youtu.be/kCc8FmEb1nY?si=LlLJEVIP3E9ltZ4X)\n",
        "\n",
        "Thanks to [Luckyluuuc/GPTmodel](https://github.com/Luckyluuuc/GPTmodel) for the original code base.\n"
      ],
      "metadata": {
        "id": "tZ_6pSGKWUaT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vSmTn7BgqLX",
        "outputId": "2abcf45b-0dac-4024-efe1-b0f8faeb112c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU :  True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "debug =  False\n",
        "monitoring = False # set to true if you want to monitor during the training with the wandb librairie\n",
        "word_level = True #if word level is set to True the model will predict word by word , else character by character\n",
        "cfg = {\n",
        "    'description' :\"entrainement classique\",\n",
        "    'batch_size': 64,\n",
        "    'block_size': 128,\n",
        "    'max_iters': 3000,\n",
        "    'eval_interval': 200,\n",
        "    'learning_rate': 1e-4,\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    'eval_iters': 200,\n",
        "    'n_embed': 256, #should be divisible by num_head\n",
        "    'num_heads': 8,\n",
        "    'num_blocks': 6,\n",
        "    'dropout': 0.4,\n",
        "    'fraction_training_data': 0.9,\n",
        "    'word_level' : word_level\n",
        "}\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "print(\"GPU : \",  torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YWw8O-VV8HRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be6f68d-816f-4c23-d0b5-daed4a4406c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.26.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.9.0 (from gradio)\n",
            "  Downloading gradio_client-1.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.26.0-py3-none-any.whl (46.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.9.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.6/322.6 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m133.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.26.0 gradio-client-1.9.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.6 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n",
            "--2025-04-23 20:44:34--  https://raw.githubusercontent.com/Luckyluuuc/GPTmodel/main/data/harry-potter-7.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1453073 (1.4M) [text/plain]\n",
            "Saving to: ‘harry-potter-7.txt’\n",
            "\n",
            "harry-potter-7.txt  100%[===================>]   1.39M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-04-23 20:44:35 (140 MB/s) - ‘harry-potter-7.txt’ saved [1453073/1453073]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download libriairies, code and data that we need\n",
        "\n",
        "if monitoring : # install the librairie wandb to monitor the loss etc..\n",
        "  !pip install wandb\n",
        "\n",
        "#install gradio\n",
        "!pip install gradio\n",
        "#my files with classes and functions\n",
        "#Training corpus:\n",
        "!wget https://raw.githubusercontent.com/Luckyluuuc/GPTmodel/main/data/harry-potter-7.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tjrWhgLAgDgO"
      },
      "outputs": [],
      "source": [
        "#import the librairies\n",
        "\n",
        "#pytorch:\n",
        "# torch already imported above\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "#to monitor :\n",
        "if monitoring : import wandb\n",
        "from tqdm.auto import tqdm # for the progress bar\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# to have a nice interface to generate text\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "M8zWmPxhFy_i"
      },
      "outputs": [],
      "source": [
        "if monitoring: wandb.init(project='GPT Harry potter word level', config=cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNDDzOU1bMp-"
      },
      "source": [
        "### Download and prepare the data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Data utils\n",
        "import torch\n",
        "import re\n",
        "\n",
        "#-----------------\n",
        "\n",
        "def tokenize_text(text): #function to transform the text in a list of word when we want to train the model at word level\n",
        "    # Use a regular expression to tokenize the text into words while preserving spaces and line breaks\n",
        "    tokens =  re.findall(r'\\w+|[\\.,;!?\"]+|\\n|\\t|.', text)\n",
        "    return tokens\n",
        "#-----------------\n",
        "def mapp(text): # return 2 dictionnaries mapping each token to an integers and vice versa\n",
        "  list_token = sorted(list(set(text)))\n",
        "  vocab_size = len(list_token)\n",
        "  stoi = {c:i for i,c in enumerate(list_token)}\n",
        "  itos = {i:c for i,c in enumerate(list_token)}\n",
        "\n",
        "  return vocab_size, stoi, itos\n",
        "#-----------------\n",
        "\n",
        "def splitting_data(frac, data): #split the data in validation_set and training_set\n",
        "    z = int(frac*len(data))\n",
        "    train_set = data[:z]\n",
        "    validation_set = data[z:]\n",
        "    return train_set, validation_set\n",
        "\n",
        "#-----------------\n",
        "\n",
        "def encode(text, stoi): #encode a list of token into a list of integers\n",
        "  list_integers = []\n",
        "  for c in text:\n",
        "    list_integers.append(stoi.get(c, 2)) # if the word is not in the dictionary it encode it as a space\n",
        "\n",
        "  return list_integers\n",
        "\n",
        "#-----------------\n",
        "\n",
        "def decode(list_integers, itos): #decode a list of integer into a string\n",
        "  text = []\n",
        "  for i in list_integers:\n",
        "    text.append(itos.get(i))\n",
        "\n",
        "  text = ''.join(c for c in text) #delete this line if you want a list of token instead of a str\n",
        "  return text\n",
        "\n",
        "#-----------------\n",
        "\n",
        "def get_batch(split, block_size, batch_size, device, train_set, validation_set): #split is either \"train\" or \"eval\"\n",
        "  assert split in [\"train\", \"eval\"], \"split must be 'train' or 'eval'\"\n",
        "  data = train_set if split == \"train\" else validation_set\n",
        "\n",
        "  ix = torch.randint(0, len(data) - block_size-1, (batch_size,)) # return a tensor of shape (batch_size) with random values between 0 and len(data) - block_size\n",
        "\n",
        "  x = torch.stack([torch.tensor(data[i:i + block_size]) for i in ix])\n",
        "  y = torch.stack([torch.tensor(data[i + 1:i + block_size + 1]) for i in ix])\n",
        "\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  return x, y\n",
        "#-----------------\n",
        "#objective : calculate the training/validation loss on several iters (\"eval_iters\" iterations)\n",
        "@torch.no_grad() #we don't want to calculate any gradient with this function\n",
        "def estimate_loss(m, eval_iters, train_set, evalutation_set, block_size, batch_size, device):\n",
        "  out = {}\n",
        "  m.eval() # to desactivate layer that are relevant in training only, e.g. dropout\n",
        "  for split in [\"train\", \"eval\"]: # we calculate the loss on both the training set and validation set\n",
        "    losses = torch.zeros(eval_iters)\n",
        "    for k in range(eval_iters):\n",
        "      X, Y = get_batch(split, block_size, batch_size, device, train_set, evalutation_set)\n",
        "      logits, loss = m(X, Y)\n",
        "      losses[k] = loss.item()\n",
        "    out[split] = losses.mean()\n",
        "  m.train()\n",
        "  return out\n",
        "#-----------------\n",
        "\n",
        "class WeightManager: #class to manage the savings of the weigths\n",
        "    def __init__(self, file_path):\n",
        "        self.file_path = file_path\n",
        "\n",
        "    def save_weights(self, model):\n",
        "        torch.save(model.state_dict(), self.file_path)\n",
        "\n",
        "    def load_weights(self, model):\n",
        "        model.load_state_dict(torch.load(self.file_path))\n",
        "        model.eval()  # Set the model to evaluation mode"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YXeO9liiXVjP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlxPV34vamEH",
        "outputId": "3b427770-b2e9-4e02-f284-36ae6ea089c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters:  1346804\n",
            "\n",
            "\n",
            " An extract of the data : \n",
            "\n",
            "\n",
            "  \u001b[31m  ? demanda le plus grand des deux.\n",
            "\n",
            "— Excellentes, répondit Severus Rogue.\n",
            "\n",
            "Le chemin était bordé à gauche par des mûriers sauvages aux tiges basses et, à droite, par une haute\n",
            "haie soigneusement taillée. Les longues capes des deux hommes ondulaient autour de leurs chevilles\n",
            "au rythme de leurs pas.\n",
            "\n",
            "— J’ai cru que j’allais arriver en retard, dit Yaxley, dont le visage taillé à coups de serpe apparaissait\n",
            "et disparaissait sous les branches des arbres qui masquaient par endroits la lueur de la lune. C’était un\n",
            "peu plus difficile que je ne l’avais pensé. Mais j’espère qu’il sera satisfait. Tu as l’air sûr de toi. Tu\n",
            "penses que tu seras bien reçu ?\n",
            "\n",
            "Rogue acquiesça d’un signe de tête mais ne donna pas de détails. Ils tournèrent à droite, dans une\n",
            "large allée qui s’éloignait du chemin. La haute haie suivit la même courbe, s’étendant au loin, par-\n",
            "delà l’impressionnant portail de fer forgé qui barrait la route des deux hommes. Ni l’un ni l’autre ne\n",
            "ralentit l’allure : sans un mot, ils levère\n",
            "\u001b[0m \n",
            "\n",
            "\n",
            " An extract of 20 tokens [' ', 'salut', ' ', 'et', ' ', 'traversèrent', ' ', 'la', '\\n', 'grille', ' ', 'comme', ' ', 'si', ' ', 'le', ' ', 'métal', ' ', 'sombre']\n"
          ]
        }
      ],
      "source": [
        "with open('/content/harry-potter-7.txt', 'r', encoding='utf-8') as f: # choose the training corpus here\n",
        "    text = f.read()\n",
        "print(\"length of dataset in characters: \", len(text))\n",
        "if len(text) < 1000000 : print(\"the length of the corpus is less than 1M characters it might be to small\")\n",
        "print( \"\\n\\n An extract of the data : \\n\\n\\n \" ,\"\\033[31m\", text[1000:2000])\n",
        "\n",
        "if word_level :\n",
        "  text = tokenize_text(text)\n",
        "\n",
        "print('\\033[0m', \"\\n\\n\\n\", \"An extract of 20 tokens\",list(text[1000:1020]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esV1rfQncxLV"
      },
      "source": [
        "### Create a map between characters and integers\n",
        "**Objective**: associate to each characters to an integers using dictionnaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JewWArZibmzp"
      },
      "outputs": [],
      "source": [
        "vocab_size, stoi, itos = mapp(text) #we assign to each token an integers and itos and stoi are the dictionnaries that allow to pass from one to the other and vice versa\n",
        "data_tok = encode(text, stoi) # we tranform our text into a list of integers thanks to the dictionnary stoi\n",
        "\n",
        "if debug:\n",
        "  print(\"vocab_size :\", vocab_size)\n",
        "  print(\"stoi :\", stoi)\n",
        "  print(\"itos :\", itos)\n",
        "  print(\"First 100 token of the encoded text : \", data_tok[:100])\n",
        "\n",
        "#splitting the data -> one for training and one for evaluating (cross_validation)\n",
        "\n",
        "train_set, validation_set = splitting_data(cfg.get('fraction_training_data'), data_tok)\n",
        "\n",
        "if debug:\n",
        "  print(\"\")\n",
        "  print(\"train set -> length :\", len(train_set))\n",
        "  print(train_set[:50])\n",
        "  print(\"validation set -> length :\", len(validation_set))\n",
        "  print(validation_set[:50])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DjvXjQl4JMH"
      },
      "source": [
        "# GPT Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Head Self-Attention\n",
        "\n",
        "\n",
        "\n",
        "### Head\n",
        "\n",
        "A single self-attention head:\n",
        "- Projects input into queries (Q), keys (K), and values (V)\n",
        "- Computes scaled dot-product attention with causal masking\n",
        "- Applies dropout to attention weights\n",
        "\n",
        "**Formulas**:\n",
        "\n",
        "- Projections:  \n",
        "  $$\n",
        "  Q = XW^Q,\\quad K = XW^K,\\quad V = XW^V\n",
        "  $$\n",
        "\n",
        "- Attention scores (scaled dot-product):  \n",
        "  $$\n",
        "  A = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)\n",
        "  $$\n",
        "\n",
        "- Output:  \n",
        "  $$\n",
        "  \\text{Attention}(Q, K, V) = A \\cdot V\n",
        "  $$\n",
        "\n",
        "### MultiHeadAttention\n",
        "\n",
        "- Applies multiple heads in parallel\n",
        "- Concatenates their outputs\n",
        "- Applies a final linear projection\n",
        "\n",
        "**Formula**:\n",
        "\n",
        "$$\n",
        "\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, \\dots, \\text{head}_h)W^O\n",
        "$$\n",
        "\n",
        "Where each head is computed as:  \n",
        "$$\n",
        "\\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)\n",
        "$$"
      ],
      "metadata": {
        "id": "w_wt_3GfPIEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from binascii import a2b_base64\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# --------------- Head --------------#\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\"\n",
        "    A single self-attention head.\n",
        "\n",
        "    Args:\n",
        "        cfg (dict): Configuration parameters.\n",
        "        head_size (int): Dimensionality for keys, queries, and values.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cfg, head_size):\n",
        "        super().__init__()\n",
        "        # Define linear layers for keys, queries, and values.\n",
        "        # Input dim is cfg['n_embed'], output dim is head_size.\n",
        "        # No bias in these layers.\n",
        "\n",
        "        # Create a causal attention mask (lower triangular matrix).\n",
        "        # Use torch.tril and register it as a buffer.\n",
        "\n",
        "        # Dropout layer using cfg['dropout'].\n",
        "        # pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, time_steps, embedding_dim)\n",
        "        # Get batch size, time steps, and embedding dimension from x\n",
        "        # Apply linear layers to get keys, queries, and values\n",
        "        # Compute attention scores: query @ key.T\n",
        "        # Scale scores by sqrt of head_size\n",
        "\n",
        "        # Apply causal mask: mask out future positions by setting them to -inf\n",
        "\n",
        "        # Apply softmax to get attention weights\n",
        "\n",
        "        # Apply dropout to attention weights\n",
        "\n",
        "        # Multiply attention weights by values to get the output\n",
        "\n",
        "        # Return the result with shape (batch, time, head_size)\n",
        "        pass\n",
        "\n",
        "\n",
        "# --------------- Multi Head --------------#\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-head self-attention using several parallel attention heads.\n",
        "\n",
        "    Args:\n",
        "        cfg (dict): Configuration parameters.\n",
        "        head_size (int): Size of each attention head.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cfg, head_size):\n",
        "        super().__init__()\n",
        "        # Create a list of attention heads (cfg['num_heads'] total).\n",
        "        # Each head is an instance of the Head class.\n",
        "\n",
        "        # Linear projection layer to combine the heads' outputs.\n",
        "        # Input and output dims are cfg['n_embed'].\n",
        "\n",
        "        # Dropout layer after projection.\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply each attention head to the input and concatenate the results along the last dim\n",
        "\n",
        "        # Apply the final linear projection to the concatenated result\n",
        "\n",
        "        # Apply dropout and return the final output\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "x1FAr6nsMZqH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title MultiHead Attention (solved)\n",
        "import torch\n",
        "\n",
        "# --------------- Head --------------#\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\"\n",
        "    Defines a single attention\n",
        "    Args:\n",
        "        cfg (dict): Configuration parameters.\n",
        "        head_size (int): Size of the head =>  head_size = d_k = d_v if we are used to the notation of the original paper \"Attention is all you need\"\n",
        "    \"\"\"\n",
        "\n",
        "    # For the forward methods:\n",
        "    # Input of size (batch, time-step, channels)\n",
        "    # Output of size (batch, time-step, head size)\n",
        "\n",
        "    def __init__(self,cfg, head_size):\n",
        "        super().__init__()\n",
        "\n",
        "         # Linear transformations (just matrix multiplication without even a bias) for keys, queries, and values\n",
        "        self.values = nn.Linear(cfg['n_embed'], head_size, bias=False)\n",
        "        self.keys = nn.Linear(cfg['n_embed'], head_size, bias=False)\n",
        "        self.queries = nn.Linear(cfg['n_embed'], head_size, bias=False)\n",
        "\n",
        "        # for the self mask attention\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(cfg['block_size'], cfg['block_size'])))\n",
        "        self.dropout = nn.Dropout(cfg['dropout']) #we use dropout in order to prevent/reduce overfitting\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x.shape: (batch, time-step, channels)\n",
        "        B, T, C = x.shape\n",
        "        key = self.keys(x)  # (B, T, head_size)\n",
        "        query = self.queries(x)  # (B, T, head_size)\n",
        "        value = self.values(x)  # same\n",
        "        energy = query @ key.transpose(-2, -1) # compute the dot product between QK^T\n",
        "        energy = energy / (query.shape[-1] ** 0.5)  # (B, T, T)\n",
        "        energy = energy.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\")) #fill the mask part by -inf so that after the softmax it will output 0\n",
        "\n",
        "        energy = F.softmax(energy, dim=-1)\n",
        "        energy = self.dropout(energy)\n",
        "        out = energy @ value  # (B, T, C)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "# --------------- Multi Head --------------#\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Using the head class, it implements the multi_head attention.\n",
        "\n",
        "    The idea is to use different head, so that each head can specialize in something different.\n",
        "    And at the end we concatenate the result so that we have a more complete embedding\n",
        "\n",
        "    Args:\n",
        "        cfg (dict): Configuration parameters.\n",
        "        head_size (int): Size of each attention head.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg, head_size):\n",
        "        super().__init__()\n",
        "        # Create a list of 'num_heads' attention heads\n",
        "        self.heads = nn.ModuleList([Head(cfg, head_size) for _ in range(cfg['num_heads'])])\n",
        "        self.proj = nn.Linear(cfg['n_embed'], cfg['n_embed'])\n",
        "        self.dropout = nn.Dropout(cfg['dropout'])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.cat([h(x) for h in self.heads], dim=-1) #concatenation of the result of the different heads, dim = (B, T, head_size*num_head = n_embed)\n",
        "        out = self.proj(x)\n",
        "        out = self.dropout(out)\n",
        "        return out"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZXPCzJbLBP-J"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feed Forward"
      ],
      "metadata": {
        "id": "r4XJxw9ACdLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------- Feedforward --------------#\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple position-wise feedforward network used in transformers.\n",
        "\n",
        "    This layer projects up the embedding dimension, applies a non-linearity,\n",
        "    then projects back down — all applied independently to each position.\n",
        "\n",
        "    Args:\n",
        "        cfg (dict): Configuration parameters, including:\n",
        "            - 'n_embed': embedding dimension\n",
        "            - 'dropout': dropout probability\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "\n",
        "        # First linear layer expands the embedding dimension by a factor of 4\n",
        "        # as recommended in the original Transformer paper.\n",
        "\n",
        "        # Second linear layer brings it back to the original embedding dimension.\n",
        "\n",
        "        # Dropout layer to regularize the output.\n",
        "\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply first linear layer to increase dimensionality\n",
        "\n",
        "        # Apply ReLU activation\n",
        "\n",
        "        # Project back to the original embedding size\n",
        "\n",
        "        # Apply dropout and return result\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "Eg_JVbymM5Xv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title FeedForward (solved)\n",
        "\n",
        "# --------------- Feedforward --------------#\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "\n",
        "        # The first linear layer increases the dimensionality by a factor of 4, same factor described in the original paper\n",
        "        self.linear = nn.Linear(cfg['n_embed'], 4 * cfg['n_embed'])\n",
        "        self.linear2 = nn.Linear(4 * cfg['n_embed'], cfg['n_embed']) # Projecting back to the original embedding size\n",
        "        self.dropout = nn.Dropout(cfg['dropout'])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.dropout(x)\n",
        "        return x"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ebckSpqcCiXr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Block and GPT"
      ],
      "metadata": {
        "id": "-goNbNkfCkUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------- Block --------------#\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\"\n",
        "    A single Transformer decoder block combining multi-head self-attention,\n",
        "    feedforward network, layer norm, and skip connections.\n",
        "\n",
        "    Args:\n",
        "        cfg (dict): Configuration dictionary with model parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "\n",
        "        # Compute the size of each attention head\n",
        "        # Usually: embedding size / number of heads\n",
        "\n",
        "        # Create a multi-head attention module\n",
        "\n",
        "        # Create a feedforward network\n",
        "\n",
        "        # Add two layer normalization layers: one before attention, one before feedforward\n",
        "\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply first layer norm to input, then pass through attention\n",
        "        # Add skip connection: input + attention output\n",
        "\n",
        "        # Apply second layer norm, then pass through feedforward\n",
        "        # Add skip connection again\n",
        "\n",
        "        # Return final output\n",
        "        pass\n",
        "\n",
        "# --------------- GPT Model --------------#\n",
        "\n",
        "class GPTmodel(nn.Module):\n",
        "    \"\"\"\n",
        "    GPT-style Transformer model for language modeling.\n",
        "\n",
        "    Args:\n",
        "        cfg (dict): Model configuration dictionary.\n",
        "        vocab_size (int): Number of tokens in the vocabulary.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cfg, vocab_size):\n",
        "        super().__init__()\n",
        "\n",
        "        # Save configuration for later use\n",
        "        # Create token embedding layer (vocab_size → embedding dim)\n",
        "\n",
        "        # Create position embedding layer (block_size → embedding dim)\n",
        "\n",
        "        # Create a stack of Transformer blocks using nn.Sequential\n",
        "        # Add a final layer norm after the last block\n",
        "\n",
        "        # Create a final linear projection to convert to vocabulary logits\n",
        "\n",
        "        pass\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        # idx shape: (batch, time). Contains token indices.\n",
        "\n",
        "        # Get token and position embeddings\n",
        "        # Sum both to get input to Transformer blocks\n",
        "\n",
        "        # Pass through the Transformer block stack\n",
        "\n",
        "        # Apply final linear projection to get logits\n",
        "\n",
        "        # If targets are provided, compute cross-entropy loss\n",
        "\n",
        "        # Return logits and optionally the loss\n",
        "        pass\n",
        "\n",
        "    def generate(self, idx, max_new_tok):\n",
        "        \"\"\"\n",
        "        Generates text by sampling from the model one token at a time.\n",
        "\n",
        "        Args:\n",
        "            idx (Tensor): Current token indices of shape (batch, current_len).\n",
        "            max_new_tok (int): Number of new tokens to generate.\n",
        "        \"\"\"\n",
        "\n",
        "        for i in range(max_new_tok):\n",
        "            # Ensure the input does not exceed the block size (crop if necessary)\n",
        "\n",
        "            # Get logits from the model (only keep the last token's logits)\n",
        "\n",
        "            # Convert logits to probabilities using softmax\n",
        "\n",
        "            # Sample the next token from the probability distribution\n",
        "\n",
        "            # Append the predicted token to the input\n",
        "\n",
        "            pass\n",
        "\n",
        "        return idx\n",
        "\n"
      ],
      "metadata": {
        "id": "jWRcui2oNLuK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title GPTModel (solved)\n",
        "\n",
        "# --------------- Block --------------#\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\"\"\n",
        "    Putting all together to build the transformer (decoder) block\n",
        "\n",
        "    Args:\n",
        "        cfg (dict): Configuration parameters.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        head_size = cfg['n_embed'] // cfg['num_heads'] # headsize is\n",
        "        self.sa = MultiHeadAttention(cfg, head_size)\n",
        "        self.ffn = FeedForward(cfg)\n",
        "        self.ln1 = nn.LayerNorm(cfg['n_embed'])\n",
        "        self.ln2 = nn.LayerNorm(cfg['n_embed'])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_sa = self.sa(x)\n",
        "        x_ffn = self.ffn(x)\n",
        "        x = x + x_sa  # here we use skip connection (meaning that add the input of one part of the nn to the output)\n",
        "        x = x + x_ffn # it helps when we calculate the gradient during the training loop\n",
        "        return x\n",
        "\n",
        "# --------------- GPT Model --------------#\n",
        "\n",
        "class GPTmodel(nn.Module):\n",
        "    \"\"\"\n",
        "    Defines the GPT model from one end to the other\n",
        "\n",
        "    Args:\n",
        "        cfg (dict): Configuration parameters.\n",
        "        vocab_size (int): Size of the vocabulary.\n",
        "\n",
        "    Methods:\n",
        "        forward(idx, targets): Forward pass for the GPT model.\n",
        "        generate(idx, max_new_tok): Generates new text using the GPT model.\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg, vocab_size):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.token_embedding = nn.Embedding(vocab_size, cfg['n_embed'])\n",
        "        self.position_embedding = nn.Embedding(cfg['block_size'], cfg['n_embed'])\n",
        "        self.attention_blocks = nn.Sequential(\n",
        "            *[Block(cfg) for _ in range(cfg['num_blocks'])],\n",
        "            nn.LayerNorm(cfg['n_embed']),\n",
        "        )\n",
        "        self.linear = nn.Linear(cfg['n_embed'], vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        tok_embed = self.token_embedding(idx) # we associate each word an embedding vector, embedding learned throught the training\n",
        "        pos_embed = self.position_embedding(torch.arange(T, device=self.cfg['device'])) # same for the the position embedding\n",
        "        x = pos_embed + tok_embed # we will feed to the attention block the sum of those 2 previous embeddings\n",
        "        logits = self.attention_blocks(x)\n",
        "        logits = self.linear(logits) # a last linear transformation to have an ouput of the size of the vocabulary\n",
        "\n",
        "        # if there is a target (pass as argument), we want to compute and return the loss\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B * T, C) # the cross entropy loss expect an input of the shape Batch * Channel\n",
        "            targets = targets.view(B * T) # and for the target just a one dimension tensor\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tok):\n",
        "\n",
        "        for i in range(max_new_tok):\n",
        "            #the context cannot extend the block_size otherwise it will generate an error when we embded the position so we crop it if needed\n",
        "            idx_crop = idx[:, -self.cfg['block_size']:]\n",
        "            logits, loss = self(idx_crop)\n",
        "\n",
        "            logits = logits[:, -1, :] #we take the last result because it represent the word to predict\n",
        "            probs = F.softmax(logits, dim=-1) # we apply a softmax to get probabilities\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # then we use thoses probabilities to choose the next word according to those probs\n",
        "\n",
        "            idx = torch.cat((idx, idx_next), dim=1) #we add the index of the word we predict in order for it to be use as context for next predictions\n",
        "\n",
        "        return idx"
      ],
      "metadata": {
        "id": "3P-AAsBBBCT4",
        "cellView": "form"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT Training"
      ],
      "metadata": {
        "id": "-3KpHGGvC-vL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks_6r6AEyc8R",
        "outputId": "9c904dcb-1e11-4f23-95b1-a5fa3a114514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "touffuesrejetteinscritprononçait26ENQUÊTEcomportémonteessaierontmatièresentirmentonmanquantdébattrechuchotaapparutconsolermarchenthabiterasbraiséloupelégèrementsortVOTREsouciaitrépandantLorsfraisescapturésattendchansonvitesseabattaitbrûlaampleraisonnablementenvoyeraffirméattendronsFlagrancesemainerêvesépouseacharnementémergeaBarrrnyenleverinvinciblesVraimentdéfenseabattudeboutassistaitpossibilitéRavitraînanteWaoochaloupéeeffleurermarionnetteterritoiresapprochaitsuivierevêchesoulevaitbénéficionsfixéaffecterhurléfonctionsauceépargnerreviensAujourdagenouillerévidentfourprovoquéeélémentperceptiblesferméesbusteproblèmesmatérialisacombattonsdisposéesseuilduretésoutenucontrôlerEncorevoulonsamplifiarudimentairesentourégarantithabiterépugnaitinstantanément\n"
          ]
        }
      ],
      "source": [
        "m = GPTmodel(cfg, vocab_size)\n",
        "m = m.to(cfg.get('device'))\n",
        "\n",
        "#weight manager to save weigths\n",
        "w = WeightManager(\"/content/weights.pth\") #be careful to choose the right path\n",
        "# to test the model before training maybe we could make all of this in the generate function\n",
        "idx = torch.zeros((1,1), dtype=torch.long, device=cfg.get('device'))\n",
        "print(decode(m.generate(idx, max_new_tok=100)[0].tolist(), itos))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796,
          "referenced_widgets": [
            "641139a945d5440ca9e73373180d4709",
            "58769eac6c5c41ef8998d1c1ffd43620",
            "ecc1569d72d54f0c8ae9f91728260086",
            "dce2d308a1114519b3dd6725cc94a920",
            "fc81f58c181a4d2ba66fde0e3280e5ab",
            "2e4dacb6a16643e3883dd81b0399bc58",
            "dedef0bd719b4ab183f6bbb21d21b441",
            "6d46a7671d134717b5eaae462df0fb80",
            "2ad6b73fb2144170a4c6fcd7237da31f",
            "ac630ba6263a4b40ab60eed453aae01e",
            "15281745764f41d29b0a31631f527a68"
          ]
        },
        "id": "fZ6wdm4iiB72",
        "outputId": "43bc010e-1190-4301-f12d-aa3814024a63"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "641139a945d5440ca9e73373180d4709"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0/3000: train loss 9.7041, val loss 9.7015  Saving weights\n",
            "step 200/3000: train loss 3.6092, val loss 3.6246  Saving weights\n",
            "step 400/3000: train loss 3.4603, val loss 3.4894  Saving weights\n",
            "step 600/3000: train loss 3.4056, val loss 3.4553  Saving weights\n",
            "step 800/3000: train loss 3.3415, val loss 3.4007  Saving weights\n",
            "step 1000/3000: train loss 3.2342, val loss 3.2984  Saving weights\n",
            "step 1200/3000: train loss 3.1302, val loss 3.2086  Saving weights\n",
            "step 1400/3000: train loss 2.9992, val loss 3.0906  Saving weights\n",
            "step 1600/3000: train loss 2.8943, val loss 3.0063  Saving weights\n",
            "step 1800/3000: train loss 2.8092, val loss 2.9390  Saving weights\n",
            "step 2000/3000: train loss 2.7431, val loss 2.8859  Saving weights\n",
            "step 2200/3000: train loss 2.6840, val loss 2.8450  Saving weights\n",
            "step 2400/3000: train loss 2.6344, val loss 2.8140  Saving weights\n",
            "step 2600/3000: train loss 2.5932, val loss 2.7847  Saving weights\n",
            "step 2800/3000: train loss 2.5539, val loss 2.7584  Saving weights\n",
            "step 2999/3000: train loss 2.5195, val loss 2.7464  Saving weights\n",
            "\n",
            " End of training\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#train the model\n",
        "#create the optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=cfg.get(\"learning_rate\"))\n",
        "\n",
        "#train\n",
        "def training(m,w, max_iters, eval_interval, eval_iters, block_size, batch_size, device, train_set, validation_set ):\n",
        "\n",
        "  best_loss = 100\n",
        "  progress_bar = tqdm(range(max_iters)) # instanciation of the pogress bar\n",
        "  train_losses = []  # List to store training losses\n",
        "  val_losses = []  # List to store validation losses\n",
        "  step_values = []  # List to store step values\n",
        "\n",
        "\n",
        "  for step in range (max_iters):\n",
        "    xb, yb = get_batch(\"train\", block_size, batch_size , device, train_set, validation_set)\n",
        "\n",
        "    #evaluate the loss\n",
        "    if step % eval_interval == 0 or step==max_iters-1 :\n",
        "      losses = estimate_loss(m, eval_iters, train_set, validation_set, block_size, batch_size, device)\n",
        "      msg = \"\"\n",
        "      if losses['eval'] < best_loss:\n",
        "        best_loss = losses['eval']\n",
        "        w.save_weights(m)\n",
        "        msg = \"Saving weights\"\n",
        "      print(f\"step {step}/{max_iters}: train loss {losses['train']:.4f}, val loss {losses['eval']:.4f} \", msg)\n",
        "      if monitoring : wandb.log({'train_loss': losses['train'], 'eval_loss': losses['eval'], 'step': step})\n",
        "\n",
        "      # Append losses to the lists\n",
        "      train_losses.append(losses['train'])\n",
        "      val_losses.append(losses['eval'])\n",
        "      step_values.append(step)\n",
        "\n",
        "\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    progress_bar.update(1) #step by one the progress bar\n",
        "\n",
        "  print(\"\\n\",\"End of training\")\n",
        "\n",
        "  # Plot the losses\n",
        "  plt.plot(step_values, train_losses, label='Training Loss')\n",
        "  plt.plot(step_values, val_losses, label='Validation Loss')\n",
        "  plt.xlabel('Steps')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "training(m, w,  cfg.get('max_iters'), cfg.get('eval_interval'), cfg.get('eval_iters') , cfg.get('block_size'), cfg.get('batch_size'), cfg.get('device'), train_set, validation_set)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iO8tzY6z84KG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "outputId": "c414fc8d-3137-4d4c-9611-4e18ea43898a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://4ef3e28bddebf8e5c2.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4ef3e28bddebf8e5c2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "w.load_weights(m) #to load the state of the weight where the lost were the lower or if you have weights from a previous training\n",
        "m.eval()\n",
        "\n",
        "# generate with some context\n",
        "def completion(context=\"\\n\", length=100):\n",
        "  if word_level:\n",
        "    context = tokenize_text(context)\n",
        "  indices = [encode(context, stoi)]\n",
        "  print(indices)\n",
        "  idx = torch.tensor(indices, dtype=torch.long, device=cfg.get('device'))\n",
        "  output = m.generate(idx, max_new_tok=100)\n",
        "  return decode(m.generate(output, max_new_tok=length)[0].tolist(), itos)\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    default_text = \"\\n\"\n",
        "    textbox = gr.Textbox(placeholder=\"Type here...\", lines=4, value=default_text)\n",
        "    btn = gr.Button(\"Autocomplete\")\n",
        "    slider = gr.Slider(label=\"length\", minimum=100, maximum=4000)\n",
        "\n",
        "    # define what will run when the button is clicked, here the textbox is used as both an input and an output\n",
        "    btn.click(fn=completion, inputs= [textbox,  slider], outputs=textbox, queue=False)\n",
        "\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n_jIpvaFXnBu"
      },
      "execution_count": 16,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "641139a945d5440ca9e73373180d4709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58769eac6c5c41ef8998d1c1ffd43620",
              "IPY_MODEL_ecc1569d72d54f0c8ae9f91728260086",
              "IPY_MODEL_dce2d308a1114519b3dd6725cc94a920"
            ],
            "layout": "IPY_MODEL_fc81f58c181a4d2ba66fde0e3280e5ab"
          }
        },
        "58769eac6c5c41ef8998d1c1ffd43620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e4dacb6a16643e3883dd81b0399bc58",
            "placeholder": "​",
            "style": "IPY_MODEL_dedef0bd719b4ab183f6bbb21d21b441",
            "value": "100%"
          }
        },
        "ecc1569d72d54f0c8ae9f91728260086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d46a7671d134717b5eaae462df0fb80",
            "max": 3000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ad6b73fb2144170a4c6fcd7237da31f",
            "value": 3000
          }
        },
        "dce2d308a1114519b3dd6725cc94a920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac630ba6263a4b40ab60eed453aae01e",
            "placeholder": "​",
            "style": "IPY_MODEL_15281745764f41d29b0a31631f527a68",
            "value": " 3000/3000 [18:34&lt;00:00,  9.11s/it]"
          }
        },
        "fc81f58c181a4d2ba66fde0e3280e5ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e4dacb6a16643e3883dd81b0399bc58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dedef0bd719b4ab183f6bbb21d21b441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d46a7671d134717b5eaae462df0fb80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ad6b73fb2144170a4c6fcd7237da31f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac630ba6263a4b40ab60eed453aae01e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15281745764f41d29b0a31631f527a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}